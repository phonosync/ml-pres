---
title: Collaborative Filtering
---
## Supervised Learning Setting
Feature representation (encoding)
$$\Phi: \text{item}^{(m)} \rightarrow \mathbf{x}^{(m)}=\begin{pmatrix}x_1^{(m)} \\ \vdots \\ x_N^{(m)}\end{pmatrix}$$


## Training Data

:::: {.columns}

::: {.column width="60%"}
Design matrix $\mathbf{X}$
```{=html}
<table style="border-collapse: collapse;" data-quarto-disable-processing="true">
  <tr>
    <th style="background-color: lightgrey; border: 1px solid black;">feature n &rightarrow;<br>item m &downarrow;</th>
    <th style="background-color: lightgrey; border: 1px solid black; text-align: center;">1</th>
    <th style="background-color: lightgrey; border: 1px solid black; text-align: center;">2</th>
    <th style="background-color: lightgrey; border: 1px solid black; text-align: center;" colspan=2>&hellip;</th>
    <th style="background-color: lightgrey; border: 1px solid black; text-align: center;">\(N\)</th>
  </tr>
  <tr>
    <td style="background-color: lightgrey; border: 1px solid black;">1</td>
    <td style="border: 1px solid black; text-align: center;">\(x^{1}_1\)</td>
    <td style="border: 1px solid black; text-align: center;">\(x^{1}_2\)</td>
    <td style="border: 1px solid black; text-align: center;"  colspan=2>&nbsp;</td>
    <td style="border: 1px solid black; text-align: center;">\(x^{1}_N\)</td>
  </tr>
  <tr>
    <td style="background-color: lightgrey; border: 1px solid black;">2</td>
    <td style="border: 1px solid black; text-align: center;">\(x^{2}_1\)</td>
    <td style="border: 1px solid black; text-align: center;">\(x^{2}_2\)</td>
    <td style="border: 1px solid black; text-align: center;" colspan=2>&nbsp;</td>
    <td style="border: 1px solid black; text-align: center;">\(x^{2}_N\)</td>
  </tr>
  <tr>
    <td style="background-color: lightgrey; border: 1px solid black;">&vellip;</td>
    <td style="border: 1px solid black; text-align: center;">&nbsp;</td>
    <td style="border: 1px solid black; text-align: center;">&nbsp;</td>
    <td style="border: 1px solid black; text-align: center;"  colspan=2>&nbsp;</td>
    <td style="border: 1px solid black; text-align: center;">&nbsp;</td>
  </tr>
  <tr>
    <td style="background-color: lightgrey; border: 1px solid black;">\(M\)</td>
    <td style="border: 1px solid black; text-align: center;">\(x^{M}_1\)</td>
    <td style="border: 1px solid black; text-align: center;">\(x^{M}_2\)</td>
    <td style="border: 1px solid black; text-align: center;"  colspan=2>&nbsp;</td>
    <td style="border: 1px solid black; text-align: center;">\(x^{M}_N\)</td>
  </tr>
</table>
```
:::

::: {.column width="20%"}
Ratings $\mathbf{y}$
```{=html}
<table style="border-collapse: collapse; width: 100%;" data-quarto-disable-processing="true">
  <tr>
    <th style="background-color: lightgrey; border: 1px solid black;">&nbsp<br>&nbsp</th>
  </tr>
  <tr>
    <td style="border: 1px solid black; text-align: center;">\(y^{1}\)</td>
  </tr>
  <tr>
    <td style="border: 1px solid black; text-align: center;">\(y^{2}\)</td>
  </tr>
  <tr>
    <td style="border: 1px solid black; text-align: center;">&vellip;</td>
  </tr>
  <tr>
    <td style="border: 1px solid black; text-align: center;">\(y^{M}\)</td>
  </tr>
</table>
```
:::

::::

## Learning Task
Learn a predictor, $f$, that maps an $N$-dimensional vector representation of an item (row in $\mathbf{X}$) to an output value (element in $\mathbf{y}$)

$$f\left(\mathbf{x}^{(m)}\right) \rightarrow y^{(m)}$$

* $y^{(m)} \in \{1,2,3,4,5\} \rightarrow$ classification
* $y^{(m)} \in \mathbb{R} \rightarrow$ regression

## Regression Problem
* Hypothesis, e.g. linear: $f(\mathbf{x}^{(m)})=\mathbf{\theta}^T\mathbf{x}^{(m)}$
* Loss function: $\mathcal{L}=\sum_{m=1}^{M}\left(y^{m}-f(\mathbf{x}^{(m)})\right)^2$

* $+$ regularisation
* Cost function:
$$J(\mathbf{\theta})=\frac{1}{2M}\sum_{m=1}^{M}\left(y^{m}-\mathbf{\theta}^T\mathbf{x}^{(m)}\right)^2+\frac{\lambda}{2}||\mathbf{\theta}||^2$$
* Minimise: Solve analytically or by gradient descent

## Summary

* Difficult to design expressive features
* No ratings or other user information required
* For personal recommendations data from other users is not leveraged
* No cold-start or sparsity problem
* new and less famous objects are also recommended
* Serendipity effect is not really supported

